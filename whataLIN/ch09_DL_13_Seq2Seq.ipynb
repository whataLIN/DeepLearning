{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4dabd03144be4656962a40475faae2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cca6e1992b7b43cb81f56ddb8e591820",
              "IPY_MODEL_63ef63c6d07a43fb872aba36e07249ad",
              "IPY_MODEL_c21697d6d7c8448799c88ce68a317953"
            ],
            "layout": "IPY_MODEL_06b0be0a179e4413ab0c1316aa2db451"
          }
        },
        "cca6e1992b7b43cb81f56ddb8e591820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c581409cbadb44d8bcf7824ed8d89b05",
            "placeholder": "​",
            "style": "IPY_MODEL_a314b2c7bcd0454bb94d59e796fc2e57",
            "value": "  0%"
          }
        },
        "63ef63c6d07a43fb872aba36e07249ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5469274bf2a4b4498957c69cc5ab228",
            "max": 3592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cddcd3b8620a42d3ba68d7a1e21c2f4d",
            "value": 0
          }
        },
        "c21697d6d7c8448799c88ce68a317953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed58935099d4698a914e67845dc587e",
            "placeholder": "​",
            "style": "IPY_MODEL_f3e381e7edaa459aba4554ddd24bc1ec",
            "value": " 0/3592 [00:00&lt;?, ?it/s]"
          }
        },
        "06b0be0a179e4413ab0c1316aa2db451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c581409cbadb44d8bcf7824ed8d89b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a314b2c7bcd0454bb94d59e796fc2e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5469274bf2a4b4498957c69cc5ab228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cddcd3b8620a42d3ba68d7a1e21c2f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ed58935099d4698a914e67845dc587e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3e381e7edaa459aba4554ddd24bc1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whataLIN/DeepLearning/blob/main/whataLIN/ch09_DL_13_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "Ww4ZmwhFAO7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8mUWwkM-7eSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15293ad0-ccda-432e-eb95-519c8b654a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 02:06:27--  https://github.com/BigData23th/Data/raw/main/corpus.txt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt [following]\n",
            "--2023-04-07 02:06:27--  https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253511 (248K) [text/plain]\n",
            "Saving to: ‘corpus.txt’\n",
            "\n",
            "\rcorpus.txt            0%[                    ]       0  --.-KB/s               \rcorpus.txt          100%[===================>] 247.57K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-04-07 02:06:27 (73.0 MB/s) - ‘corpus.txt’ saved [253511/253511]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tab-delimited Bilingual Sentence Pairs\n",
        "# 출처 : http://www.manythings.org/anki\n",
        "!wget https://github.com/BigData23th/Data/raw/main/corpus.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 파일을 전처리\n",
        "\n",
        "import string # punctuation\n",
        "\n",
        "l = [] # 특수문자를 지운 문장들을 받아줄 리스트\n",
        "\n",
        "# with -> torch.no_grad()? => 특정한 객체가 생성이 되었을 때 with 구문이 끝나면 close 반환\n",
        "with open(\"./corpus.txt\", 'r', encoding='utf-8') as f:\n",
        "    # open(경로, 'r', encoding=인코딩방식): 파일을 읽어와줌 (텍스트파일)\n",
        "    # with .... -> 특정한 객체를 생성시키고, with 구문이 끝나면 해당 객체를 삭제 (반환)\n",
        "    # open () as f -> open을 통해 읽어들여온 파일을 f라는 이름에 변수에 할당\n",
        "    lines = f.read().split('\\n') # '\\n' = 엔터 = 개행문자\n",
        "    # 파일을 읽어온 다음에, 엔터(줄) 기준으로 쪼개줘라 -> 문장별로 리스트화\n",
        "    # lines = ['...', '...', '문장...']\n",
        "    for line in lines: # 문장\n",
        "        # 특수문자를 지우고 모든 글자를 소문자로 변경\n",
        "        txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "        l.append(txt)"
      ],
      "metadata": {
        "id": "a-aQlWAjAo6A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "l=[]\n",
        "\n",
        "with open('./corpus.txt', 'r', encoding='utf-8') as f:  #with가 종료되면 open된 상태를 종료함\n",
        "                                                    # 끝나면 f 를 erturn하겟음\n",
        "  # print(f) - 불러온 파일 객체\n",
        "  # print(f.read()) - 파일객체를 통으로 된 문자열로서 불러옴\n",
        "  # testWrapper - 파이썬이 읽을 수 있는 형태가 되었음\n",
        "  # print(f.read().split('\\n'))   #모든 파일을 하나의 string으로 불러옴\n",
        "  lines = f.read().split('\\n')\n",
        "  # for line in lines:\n",
        "  #   txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "  #   l.append(txt)\n",
        "  l+=[\"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "      for line in f.read().split('\\n')]\n"
      ],
      "metadata": {
        "id": "LZQoMxaGeOMU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l[:5] #\\t - 탭"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0UBQQi0DBiF",
        "outputId": "0f31ec7b-142f-4c77-b787-4b5c6d7f2e56"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습용 데이터 만들기"
      ],
      "metadata": {
        "id": "9uJ7SQ2xDNlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단어가 10개를 넘지 않는 문장들만 사용\n",
        "* 문장을 불러올 때 <EOS(End Of Speech)> 토큰을 추가해서 문장이 끝났음을 알림"
      ],
      "metadata": {
        "id": "8amudxBvDUcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "Tp5Ac8oiDn24"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW를 만드는 함수 정의"
      ],
      "metadata": {
        "id": "vFh4bwZ8DoOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_BOW(corpus): # 말뭉치 -> 문장 -> BOW를 만드는 함수\n",
        "    BOW = {'<SOS>':0,'<EOS>':1}\n",
        "    # BOW 안에 문장의 시작과 끝을 알리는\n",
        "    # SOS(Start Of Speech) 토큰과 EOS(End Of Speech) 토큰을 추가\n",
        "\n",
        "    # 문장 내 단어들을 사용하여 BOW를 생성\n",
        "    for line in corpus:\n",
        "        for word in line.split():\n",
        "            if word not in BOW.keys(): # 등록되지 않은 단어면\n",
        "                BOW[word] = len(BOW.keys())\n",
        "                # 사전에 추가해주는데, 해당 단어의 고유번호는 이전까지의 키의 갯수\n",
        "    return BOW"
      ],
      "metadata": {
        "id": "WrQ7qjwYD05b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습용 데이터셋 정의"
      ],
      "metadata": {
        "id": "zD_EagauE2fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Eng2Kor(Dataset):\n",
        "    def __init__(self, path='./corpus.txt') -> None:\n",
        "        super().__init__()\n",
        "        self.eng_corpus = [] # 영어문장이 들어가는 변수\n",
        "        self.kor_corpus = [] # 한글문장이 들어가는 변수\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "            for line in lines: # 문장\n",
        "                txt = \"\".join(v for v in line\n",
        "                              if not v in string.punctuation).lower()\n",
        "                # \\t 구분이 되어 있었음 (영어와 한글) -> 탭을 기준으로 분리\n",
        "                engtxt, kortxt = txt.split('\\t') # 0 : 영어 # 1 : 한글\n",
        "                # engtxt = txt.split('\\t')[0]\n",
        "                # kortxt = txt.split('\\t')[1]\n",
        "\n",
        "                # 길이가 10 이하인 문장 = 단어의 갯수가 10개 이하인 문장만 학습\n",
        "                if not (len(engtxt.split()) <= 10 and len(kortxt.split())<=10):\n",
        "                    continue\n",
        "                    # 영어, 한글 번역문 모두 10개 단어 이하인 데이터만 사용\n",
        "                self.eng_corpus.append(engtxt)\n",
        "                self.kor_corpus.append(kortxt)\n",
        "        \n",
        "        # 영어와 한글 문장을 각각 BOW(단어 사전)으로 변환\n",
        "        self.engBOW = get_BOW(self.eng_corpus)\n",
        "        self.korBOW = get_BOW(self.kor_corpus)\n",
        "    \n",
        "    # 문장을 단어별로 분리하는 함수\n",
        "    def gen_seq(self, line): # line = 문장\n",
        "        seq = line.split()  # 토큰화 한다음에\n",
        "        seq.append(\"<EOS>\")  # 마지막에 EOS(문장 끝) 토큰 추가\n",
        "        return seq\n",
        "\n",
        "    def __len__(self): # 데이터의 개수를 반환하는 함수\n",
        "        return len(self.eng_corpus)\n",
        "\n",
        "    # 데이터와 정답을 반환하는 함수\n",
        "    def __getitem__(self, i): # data, label을 지정\n",
        "        # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n",
        "        # 1) 영어 corpus 중 i번째 문장을 받아옴\n",
        "        # 2) gen_seq -> i번째 문장을 seq 형태로 변환 (토큰+EOS)\n",
        "        # 3) 단어 사전을 사용해서 고유번호 형태로 변환 (학습을 위해 숫자형태로 변환)\n",
        "        #self.eng_corpus[i] -> self.gen_seq(self.eng_corpus[i])\n",
        "        # -> 리스트컴프리헨션으로 대칭시킹 : [ for in self.gen_seq(self.eng_corpus)]\n",
        "        data = np.array([\n",
        "            [self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])]\n",
        "        ])\n",
        "        label = np.array([\n",
        "            [self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])]\n",
        "        ])\n",
        "        return data, label # 영어 데이터 (입력) -> 한글 데이터 (정답)"
      ],
      "metadata": {
        "id": "jFiIQebMEwD_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로더"
      ],
      "metadata": {
        "id": "7hyu5o55qrQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(dataset): # 데이터셋의 문장을 한 문장씩 불러오기 위한 함수 정의\n",
        "    for i in range(len(dataset)):\n",
        "        data, label = dataset[i]\n",
        "\n",
        "        # 데이터와 정답을 반환\n",
        "        yield torch.tensor(data), torch.tensor(label)\n",
        "        # yield : 리턴과 유사, 값을 반복적으로 반환"
      ],
      "metadata": {
        "id": "8_zGEJvFqrBs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의"
      ],
      "metadata": {
        "id": "UPINig5DrTOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 정의\n",
        "* 임베딩층, GRU층"
      ],
      "metadata": {
        "id": "za-92TOSrXSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # 임베딩층\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)   #-과소표현으로\n",
        "\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)     #디폴트1로\n",
        "        # nn.GRU : GRU 계산. input_size, hidden_size, num_layers)\n",
        "    \n",
        "    def forward(self, x, h): # x: 입력값 / h : 은닉상태\n",
        "        # 배치 차원과 시계열 차원 추가\n",
        "        x = self.embedding(x).view(1,1,-1) #1,1이 배치/시계열차원\n",
        "        output, hidden = self.gru(x,h)    # output : 문장의 특성, hidden 은닉 상태\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "003BAHh4rehb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 정의\n",
        "* 임베딩 층\n",
        "* 전결합 층 (ReLU)\n",
        "* 전결합 층 (Softmax)\n",
        "* 내적\n",
        "* GRU층"
      ],
      "metadata": {
        "id": "wNA-b81Itgjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11) -> None:\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # 임베딩 층 정의\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # 어텐션 가중치를 계산하기 위한 MLP층\n",
        "        self.attention = nn.Linear(hidden_size * 2, max_length)\n",
        "\n",
        "        # 10개 + <EOS>(1) = 최대 길이 11개\n",
        "\n",
        "\n",
        "        # 특징 추출을 위한 MLP층\n",
        "        self.context = nn.Linear(hidden_size *2, hidden_size)\n",
        "\n",
        "        # 오버피팅을 피하기 위한 드롭아웃층\n",
        "        self.dropout = nn.Dropout(dropout_p)    #외부에서 수정 가능하게.\n",
        "\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size) #연속적 의미 분류\n",
        "\n",
        "        # 단어 분류를 위한 MLP층\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # 활성화 함수\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        # LogSoftmax(dim) : 소프트맥스 함수에 로그 값을 취한 것을 반환\n",
        "        # dim -> 계산의 대상이 될 차원값\n",
        "    \n",
        "    def forward(self, x, h, encoder_outputs): # x : 입력값, h : 은닉상태, e...: 인코더 결과값\n",
        "        # 입력 받은 x(현 시점의 디코더 입력)을 임베딩 층을 사용해 밀집 표현으로 변환\n",
        "        \n",
        "        x = self.embedding(x).view(1,1,-1)      # 배치 차원, 시계열 차원, 단어들의 개수.\n",
        "        x = self.dropout(torch.xlogy_)        \n",
        "\n",
        "        # 어텐션 가중치 계산\n",
        "        attn_weights = self.softmax(\n",
        "            self.attention(torch.cat((x[0], h[0], -1)))   #배치차원의 0번째, 은닉츠으이 0번째를 가지고 처리\n",
        "        )\n",
        "\n",
        "        # 어텐션 가중치와 인코더의 출력을 내적(크기가 다른 두 배열을 방향이 일치하는 만큼 곱함)\n",
        "        attn_applied = torch.bmm(\n",
        "            attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)   #가장 밖 차원을 unsqueeze\n",
        "        ) # bmm(A, B) : A 크기가 (B, N, M)이고, B 크기가 (B, M, K)\n",
        "        # => (B, N, K) 크기의 출력을 반환 > 유사도 구하기 (어텐션가중치-이전까지의 전체맥락 - 인코더출력(일치도 얼마?))\n",
        "\n",
        "        # 인코더 각 시점의 중요도와 밀집 표현을 합쳐서 MLP층으로 특징 추출\n",
        "        output = torch.cat((x[0], attn_applied[0]), 1)    #각 시점 중요도가 x의0\n",
        "        output = self.context(output).unsqueeze(0)\n",
        "        output = self.relu(output)\n",
        "        # 인코더의 중요도(attn_applied)와 현시점에서의 디코더의 밀집표현(x)을 합쳐서\n",
        "        # MLP층(context)으로 입력\n",
        "        # -> MP층은 인코더 각 시점의 중요도와 현시점 디코더의 밀집표현을 동시에 처리\n",
        "        # -> 인코더의 중요도가 디코더의 반영\n",
        "\n",
        "        # GRU층으로 입력\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        # 예측된 단어를 출력\n",
        "        output = self.out(output[0])\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "CDqJvnMJtX11"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 정의"
      ],
      "metadata": {
        "id": "IOuGn4jC44GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습에 필요한 요소 정의"
      ],
      "metadata": {
        "id": "CyiuJmmk47HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size = len(dataset.engBOW), hidden_size = 64).to(device)  #던져줌\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p = 0.1).to(device)\n",
        "\n",
        "# 인코더와 디코더 학습을 위한 최적화 함수 정의\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = Adam(decoder.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "42VTmT0Ps72D"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qZiVal6U580O",
        "outputId": "5320841a-00ea-4e85-b51e-9ccd728c84cf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 루프 정의"
      ],
      "metadata": {
        "id": "lR0tenX96W95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    iterator = tqdm(loader(dataset), total=len(dataset))\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in iterator:\n",
        "        data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "        # 인코더의 초기 은닉 상태\n",
        "        encoder_hidden = torch.zeros(1, 1, 64).to(device)    #특징이 64개로\n",
        "        # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "        # 최대 단어 10개 + 종료(EOS) -> 11개\n",
        "        encoder_outputs = torch.zeros(11,64).to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # 인코더 동작\n",
        "        for ei in range(len(data)): # data : 토큰화, 고유번호 -> 단어들의 리스트\n",
        "            # ei => data의 인덱스들\n",
        "            # 한 단어씩 인코더에 넣어줌\n",
        "            encoder_output, encoder_hidden = encoder(data[ei], encoder_hidden)\n",
        "\n",
        "            # 인코더의 은닉상태를 저장\n",
        "            encoder_output[ei] = encoder_output[0,0]    #64를 불러냄\n",
        "        \n",
        "        decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "\n",
        "        # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 지정\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # 디코더 동작\n",
        "        # 티처 포싱 (Teacher Forcing: 교사 강요)\n",
        "        # Seq2Seq 구조에서 현시점의 입력을 (모델의 예측값을 사용하는 대신에) 정답을 이용하는 방법\n",
        "        # 엉뚱한 답을 피하고, 시간 단축을 위해 강제적으로 정답을 넣어주는 기술 (50% 확률로 적용)\n",
        "        use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "        \n",
        "        if use_teacher_forcing:\n",
        "            for di in range(len(label)):\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs\n",
        "                )\n",
        "\n",
        "\n",
        "                # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "                target = torch.tensor(label[di], dtype = torch.long).to(device) \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "                decoder_input = target #바꿔치기\n",
        "\n",
        "                #데이터의 인덱스로 라벨값 호출 - \n",
        "\n",
        "        else:\n",
        "            for di in range(len(label)):\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "                \n",
        "                target = torch.tensor(label[di], dtype = torch.long).to(device) \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "\n",
        "                # 가장 높은 확률을 갖는 단어의 인덱스 topi\n",
        "                topv, topi = decoder_output.topk(1)   # top k -> 가장 높은 확률을 가진 (1)개를 불러옴\n",
        "                # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n",
        "              \n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "                \n",
        "                if decoder_input.item() == 1: #<EOS> 토큰을 만나면 중지\n",
        "                    break\n",
        "        \n",
        "        # 전체 손실 계산\n",
        "        total_loss += loss.item() / len(dataset)\n",
        "        iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pt\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pt\")"
      ],
      "metadata": {
        "id": "oM5eo7gf6UrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    iterator = tqdm(loader(dataset), total=len(dataset))\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in iterator:\n",
        "        data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "        # 인코더의 초기 은닉 상태\n",
        "        encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "        # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "        # 최대 단어 10개 + 종료(EOS) -> 11개\n",
        "        encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # 인코더 동작\n",
        "        for ei in range(len(data)): # data : 토큰화, 고유번호 -> 단어들의 리스트\n",
        "            # ei => data의 인덱스들\n",
        "            # 한 단어씩 인코더에 넣어줌\n",
        "            encoder_output, encoder_hidden = encoder(\n",
        "                data[ei], encoder_hidden)\n",
        "\n",
        "            # 인코더의 은닉상태를 저장\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "            # 1, 1, *64*\n",
        "        \n",
        "        decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "        # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 지정\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # 디코더 동작\n",
        "        # 티처 포싱 (Teacher Forcing: 교사 강요)\n",
        "        # Seq2Seq 구조에서 현시점의 입력을 (모델의 예측값을 사용하는 대신에) 정답을 이용하는 방법\n",
        "        # 엉뚱한 답을 피하고, 시간 단축을 위해 강제적으로 정답을 넣어주는 기술 (50% 확률로 적용)\n",
        "        use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "        \n",
        "        if use_teacher_forcing:\n",
        "            for di in range(len(label)): # di : data 인덱스\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs\n",
        "                )\n",
        "\n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)                \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "                \n",
        "                # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "                decoder_input = target # 바꿔치기\n",
        "        else:\n",
        "            for di in range(len(label)):\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)                \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "\n",
        "                # 가장 높은 확률을 갖는 단어의 인덱스 topi\n",
        "                topv, topi = decoder_output.topk(1) # top k -> (1)개를 불러옴\n",
        "                \n",
        "                # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n",
        "                decoder_input = topi.squeeze().detach() # 텐서 -> 값\n",
        "                \n",
        "                if decoder_input.item() == 1: #<EOS> 토큰을 만나면 중지\n",
        "                    break\n",
        "        \n",
        "        # 전체 손실 계산\n",
        "        total_loss += loss.item() / len(dataset)\n",
        "        iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pt\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "4dabd03144be4656962a40475faae2d5",
            "cca6e1992b7b43cb81f56ddb8e591820",
            "63ef63c6d07a43fb872aba36e07249ad",
            "c21697d6d7c8448799c88ce68a317953",
            "06b0be0a179e4413ab0c1316aa2db451",
            "c581409cbadb44d8bcf7824ed8d89b05",
            "a314b2c7bcd0454bb94d59e796fc2e57",
            "f5469274bf2a4b4498957c69cc5ab228",
            "cddcd3b8620a42d3ba68d7a1e21c2f4d",
            "9ed58935099d4698a914e67845dc587e",
            "f3e381e7edaa459aba4554ddd24bc1ec"
          ]
        },
        "id": "OVFHcn_XzgEG",
        "outputId": "5d948771-2ef9-4770-af67-4a1f4af18153"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3592 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dabd03144be4656962a40475faae2d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-b67003997b3d>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype=torch.long).to(device)\n",
            "<ipython-input-46-b67003997b3d>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(label, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b67003997b3d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# ei => data의 인덱스들\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# 한 단어씩 인코더에 넣어줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             encoder_output, encoder_hidden = encoder(\n\u001b[0m\u001b[1;32m     25\u001b[0m                 data[ei], encoder_hidden)\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-eb87c107ba89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 배치 차원과 시계열 차원 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1,1이 배치/시계열차원\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# output : 문장의 특성, hidden 은닉 상태\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    220\u001b[0m                     self.input_size, input.size(-1)))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 64, got 128"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
        "!wget https://github.com/BigData23th/Data/raw/main/attn_dec.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsM-EwPDLgl",
        "outputId": "09608bb3-70b0-42e6-b336-1f442c5bf706"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 03:42:12--  https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt [following]\n",
            "--2023-04-07 03:42:12--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 727147 (710K) [application/octet-stream]\n",
            "Saving to: ‘attn_enc.pt.1’\n",
            "\n",
            "attn_enc.pt.1       100%[===================>] 710.10K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-04-07 03:42:12 (103 MB/s) - ‘attn_enc.pt.1’ saved [727147/727147]\n",
            "\n",
            "--2023-04-07 03:42:13--  https://github.com/BigData23th/Data/raw/main/attn_dec.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt [following]\n",
            "--2023-04-07 03:42:13--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2857305 (2.7M) [application/octet-stream]\n",
            "Saving to: ‘attn_dec.pt.1’\n",
            "\n",
            "attn_dec.pt.1       100%[===================>]   2.72M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-07 03:42:13 (167 MB/s) - ‘attn_dec.pt.1’ saved [2857305/2857305]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 평가"
      ],
      "metadata": {
        "id": "Xj6sqB6TDZFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-See_gDDSvg",
        "outputId": "3fb0bed4-1bfe-4762-8ff8-79fd5b968465"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불러올 영어 문장을 랜덤하게 지정\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "input_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "axp4313pDnt7",
        "outputId": "f944ee94-893a-4e2b-e591-8dfb7302f172"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tom is a timid child'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\""
      ],
      "metadata": {
        "id": "2KR-fniJD-9J"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device) # 영어문장\n",
        "label = torch.tensor(label, dtype=torch.long).to(device) # 한국어문장"
      ],
      "metadata": {
        "id": "wpQit4YVEGvY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAVPvZcEbZl",
        "outputId": "125bc4db-18f7-4a27-f4e5-61ef3371435f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 52, 198, 271, 751, 900,   1]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr73uVzPEXEp",
        "outputId": "7dfed629-8daf-49aa-f379-9f18cd949be3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 103, 1153, 1450,    1]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 동작"
      ],
      "metadata": {
        "id": "mTYzESGiEtfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더의 초기 은닉 상태 정의\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "# 인코더 출력을 담기 위한 변수\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)"
      ],
      "metadata": {
        "id": "_WwZLartEu1D"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ei in range(len(data)):\n",
        "    # 한 단어씩 인코더에 넣어줌\n",
        "    encoder_output, encoder_hidden = encoder(\n",
        "        data[ei], encoder_hidden\n",
        "    )\n",
        "    # 인코더의 출력을 저장\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]"
      ],
      "metadata": {
        "id": "13okMEhfE6K5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "528e72e7-0233-4d5c-bcb5-fa076113e3db"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7b93f1099604>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 한 단어씩 인코더에 넣어줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     encoder_output, encoder_hidden = encoder(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-eb87c107ba89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 배치 차원과 시계열 차원 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#1,1이 배치/시계열차원\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# output : 문장의 특성, hidden 은닉 상태\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    219\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m    220\u001b[0m                     self.input_size, input.size(-1)))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 64, got 384"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs"
      ],
      "metadata": {
        "id": "Bumb4Mr1FP8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 동작"
      ],
      "metadata": {
        "id": "4JsCvUSrFMaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 초기 입력\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "# 0 -> 문장이 시작되었다는 SOS 토큰\n",
        "\n",
        "# 인코더의 마지막 은닉 상태 -> 디코더의 초기 은닉 상태\n",
        "decoder_hidden = encoder_hidden"
      ],
      "metadata": {
        "id": "YtbFVngTFN5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for di in range(11):\n",
        "    # 디코더 모델을 통해서 단어별 나올 확률\n",
        "    decoder_output = decoder(\n",
        "        decoder_input, decoder_hidden, encoder_outputs\n",
        "    )\n",
        "    # 가장 높은 확률을 갖는 단어의 요소 계산\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    # 가장 높은 확률의 단어\n",
        "    decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    # EOS 토큰을 만나면 중지\n",
        "    if decoder_input.item() == 1:\n",
        "        break\n",
        "    \n",
        "    # 예측 문자열에 가장 높은 확률의 단어를 추가\n",
        "    pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n",
        "\n",
        "print(input_sentence)\n",
        "print(pred_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRyfeY8OFjuB",
        "outputId": "6f1093b4-034e-4304-8dab-650a503ef636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i just want to rest\n",
            "싶어 싶어 싶어 싶어 이걸 어제 이걸 싶어 쉬고 싶어 이걸 함께 함께 이걸 싶어 싶어 싶어 싶어 싶어 싶어 싶어 이걸 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 통합"
      ],
      "metadata": {
        "id": "uQdzZcLYJi11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NyU4tGQKhrH",
        "outputId": "57ff182a-7a01-407f-968e-a1105dd76cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "\n",
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "# 디코더 가중치 불러오기\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))\n",
        "\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\"\n",
        "\n",
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "for ei in range(len(data)):\n",
        "   encoder_output, encoder_hidden = encoder(\n",
        "       data[ei], encoder_hidden)\n",
        "     \n",
        "   encoder_outputs[ei] = encoder_output[0, 0]  \n",
        "\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "decoder_hidden = encoder_hidden \n",
        "\n",
        "for di in range(11):\n",
        "   decoder_output = decoder(\n",
        "                       decoder_input, decoder_hidden, encoder_outputs)\n",
        "   topv, topi = decoder_output.topk(1)\n",
        "   decoder_input = topi.squeeze().detach()\n",
        "\n",
        "   if decoder_input.item() == 1:  \n",
        "       break\n",
        "\n",
        "   pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"  \n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from time import sleep\n",
        "\n",
        "file_name = '/content/sample.mp3'\n",
        "\n",
        "text = input_sentence\n",
        "tts_en = gTTS(text=text)\n",
        "tts_en.save(file_name)\n",
        "\n",
        "print(input_sentence)  # 영어 문장\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)\n",
        "\n",
        "sleep(4)\n",
        "\n",
        "text = pred_sentence\n",
        "tts_ko = gTTS(text=text, lang='ko')\n",
        "tts_ko.save(file_name)\n",
        "print(pred_sentence)  # 한글 문장\n",
        "\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "OmQ0IotPJkF_",
        "outputId": "25b3f18d-6d23-4327-beaf-c2166f408ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "any questions\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "아무 질문이라도 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}